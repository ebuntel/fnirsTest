{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder name:  2023-12-18_003\n",
      "Data shape:  (26, 100, 68)\n",
      "Label shape:  (26,)\n",
      "Folder name:  2023-12-15_002\n",
      "Data shape:  (26, 100, 68)\n",
      "Label shape:  (26,)\n",
      "Folder name:  2023-12-17_002\n",
      "Data shape:  (26, 100, 68)\n",
      "Label shape:  (26,)\n",
      "Folder name:  2023-12-17_001\n",
      "Data shape:  (26, 100, 68)\n",
      "Label shape:  (26,)\n",
      "Folder name:  2023-12-18_002\n",
      "Data shape:  (26, 100, 68)\n",
      "Label shape:  (26,)\n",
      "Folder name:  2023-12-18_001\n",
      "Data shape:  (26, 100, 68)\n",
      "Label shape:  (26,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load data from each folder in /data/toPreProc/\n",
    "\n",
    "data_in = 0 # Number of input dimensions to the model\n",
    "data_out = 0 # Number of output dimensions to the model\n",
    "\n",
    "data_dict = {}\n",
    "label_dict = {}\n",
    "\n",
    "for folder in os.listdir('data/toPreProc/'):\n",
    "    print(\"Folder name: \", folder)\n",
    "    data_dict[folder] = np.load(f'data/toPreProc/{folder}/{folder}PreprocessedData.npy')\n",
    "    labels = np.load(f'data/toPreProc/{folder}/{folder}Labels.npy', allow_pickle=True)\n",
    "    label_dict[folder] = labels[:-1, 2]\n",
    "    print(\"Data shape: \", data_dict[folder].shape)\n",
    "    print(\"Label shape: \", label_dict[folder].shape)\n",
    "    if(data_dict[folder].shape[1] > data_in):\n",
    "        data_in = data_dict[folder].shape[1]\n",
    "    if(label_dict[folder].shape[0] > data_out):\n",
    "        data_out = label_dict[folder].shape[0]\n",
    "\n",
    "# # One hot encode the labels\n",
    "# ohes = {}\n",
    "# num_of_labels = len(label_dict) # Includes one extra for the end of the sequence\n",
    "# for key, y in label_dict.items():\n",
    "#     #\n",
    "\n",
    "#     #\n",
    "#     print(y.reshape(-1, 1))\n",
    "#     ohes[key] = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit(y)\n",
    "#     label_dict[key] = ohes[key].transform(y)\n",
    "#     print(label_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "dropout_prob = 0.2\n",
    "\n",
    "# Define the sequential model\n",
    "model = nn.Sequential(\n",
    "    nn.BatchNorm1d(data_in),\n",
    "    nn.Dropout1d(dropout_prob),\n",
    "    nn.Conv1d(kernel_size=5, padding_mode=\"replicate\", in_channels=data_in, out_channels=64),\n",
    "    nn.MaxPool1d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Dropout1d(dropout_prob),\n",
    "    nn.Conv1d(kernel_size=3, padding_mode=\"replicate\", in_channels=64, out_channels=64),\n",
    "    nn.MaxPool1d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Dropout1d(dropout_prob),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout1d(dropout_prob),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout1d(dropout_prob), \n",
    "    nn.Linear(32, data_out),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "compiled_model = torch.compile(model)\n",
    "#model.compile(optimizer='adam', loss=nn.CrossEntropyLoss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "(13, 2, 100, 68)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "num_batches = (data_out // batch_size) # Number of batches to run based on the batch size and the number of samples\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss\n",
    "\n",
    "optimizer = torch.optim.Adam(compiled_model.parameters(), lr=0.001)\n",
    "\n",
    "batches = {}\n",
    "labels = []\n",
    "\n",
    "for i in range(num_batches):\n",
    "    # Get the batch\n",
    "    batch = []\n",
    "    for value in list(data_dict.values()):\n",
    "        #print(value)\n",
    "        batches[i] = value[i*batch_size:(i+1)*batch_size,:]\n",
    "    batch = np.array(batch)\n",
    "    #print(\"Batch = \", np.shape(batch))\n",
    "    \n",
    "    # Get the labels\n",
    "    for value in list(label_dict.values())[i*batch_size:(i+1)*batch_size]:\n",
    "        labels.append(value)\n",
    "    print(len([labels]))\n",
    "\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(np.shape(np.array(list(batches.values()))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
